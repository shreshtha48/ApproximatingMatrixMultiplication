{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hqOS9dVdrsxf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "import pandas as pd\n",
    "from scipy.linalg import orth\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "UuUSm2n3tHCy"
   },
   "outputs": [],
   "source": [
    "# The class to generate the matrices.\n",
    "class MatrixGeneration:\n",
    "\n",
    "  \"\"\"\n",
    "    The MatrixGeneration class takes three arguments in the constructor.\n",
    "\n",
    "    m: The number of rows.\n",
    "    n: The number of cols.\n",
    "\n",
    "  \"\"\"\n",
    "  def __init__(self,m,n,kappa):\n",
    "    self.m=m\n",
    "    self.n=n\n",
    "    self.kappa=kappa\n",
    "\n",
    "    ## TODO: Some places we return self.A, some places we return A.lets make it uniform.\n",
    "    #matrices with good condition number\n",
    "  def ug_matrix(self):\n",
    "    U = orth(np.random.rand(self.m, self.n))   # m x n orthonormal matrix\n",
    "    V = orth(np.random.rand(self.n, self.n))   # n x n orthonormal matrix\n",
    "    S = np.diag(np.linspace(1, 1/self.kappa, self.n))  # Diagonal scaling matrix\n",
    "    self.A = U @ S @ V   # Final matrix\n",
    "    return self.A\n",
    "\n",
    "  #nb and ng matrices are the matrices which have a bad leverage score\n",
    "  def nb_matrix(self):\n",
    "      # Determine dimensions for constructing the matrix\n",
    "      half_num_cols = int(self.n / 2)\n",
    "      top_block_rows = self.m - half_num_cols\n",
    "\n",
    "      # Random Gaussian block\n",
    "      gaussian_block = np.random.normal(0, 1, (top_block_rows, half_num_cols))\n",
    "\n",
    "      # Tiny noise block\n",
    "      tiny_noise_block = 1e-8 * np.random.rand(top_block_rows, half_num_cols)\n",
    "\n",
    "      # Identity matrix for the stable part\n",
    "      identity_block = np.identity(half_num_cols)\n",
    "\n",
    "      # Construct matrix blocks\n",
    "      top_left = self.kappa * gaussian_block\n",
    "      top_right = tiny_noise_block\n",
    "      bottom_left = np.zeros((half_num_cols, top_block_rows))\n",
    "      bottom_right = identity_block\n",
    "\n",
    "      # Assemble full matrix\n",
    "      top_half = np.hstack([top_left, top_right])\n",
    "      bottom_half = np.hstack([bottom_left[:, :half_num_cols], bottom_right])\n",
    "      A = np.vstack([top_half, bottom_half])\n",
    "\n",
    "      return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "-i0NaxlXrGrz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "class MatrixApproximationLeverage:\n",
    "    \"\"\"\n",
    "    Performs approximate matrix multiplication using leverage score sampling techniques.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def leverage_score_sampling(A: np.ndarray, B: np.ndarray, samples: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Selects rows from A and B based on leverage scores to approximate A @ B.T.\n",
    "\n",
    "        Args:\n",
    "            A (np.ndarray): Input matrix of shape (m, n)\n",
    "            B (np.ndarray): Input matrix of shape (n, p)\n",
    "            samples (int): Number of rows (and singular vectors) to use\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: Scaled sampled matrices A' and B'\n",
    "        \"\"\"\n",
    "        m, _ = A.shape\n",
    "        n, _ = B.shape\n",
    "\n",
    "        # 1) full SVD, then truncate to top-k singular vectors\n",
    "        U, _, _  = np.linalg.svd(A, full_matrices=False)\n",
    "        Ub, _, _ = np.linalg.svd(B, full_matrices=False)\n",
    "\n",
    "        Uk  = U[:, :samples]   # (m × k)\n",
    "        Ubk = Ub[:, :samples]  # (n × k)\n",
    "\n",
    "        # 2) leverage scores = row-norms² of those truncated bases\n",
    "        levA = np.sum(Uk**2,  axis=1)  # length-m\n",
    "        levB = np.sum(Ubk**2, axis=1)  # length-n\n",
    "\n",
    "        # 3) normalize to get true probability distributions\n",
    "        pA = levA / levA.sum()\n",
    "        pB = levB / levB.sum()\n",
    "\n",
    "        # 4) random sample exactly k rows according to pA, pB\n",
    "        idxA = np.random.choice(m, size=samples, replace=False, p=pA)\n",
    "        idxB = np.random.choice(n, size=samples, replace=False, p=pB)\n",
    "\n",
    "        # 5) build and scale\n",
    "        sampled_A = A[idxA, :]\n",
    "        sampled_B = B[idxB, :]\n",
    "\n",
    "        scaled_A = sampled_A * np.sqrt(m / samples)\n",
    "        scaled_B = sampled_B * np.sqrt(n / samples)\n",
    "\n",
    "        return scaled_A, scaled_B\n",
    "\n",
    "    @staticmethod\n",
    "    def sqrt_leverage_score_sampling(A: np.ndarray, B: np.ndarray, samples: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Selects rows using the square root of leverage scores.\n",
    "\n",
    "        Args:\n",
    "            A (np.ndarray): Input matrix of shape (m, n)\n",
    "            B (np.ndarray): Input matrix of shape (n, p)\n",
    "            samples (int): Number of rows (and singular vectors) to use\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: Scaled sampled matrices A' and B'\n",
    "        \"\"\"\n",
    "        m, _ = A.shape\n",
    "        n, _ = B.shape\n",
    "\n",
    "        U, _, _  = np.linalg.svd(A, full_matrices=False)\n",
    "        Ub, _, _ = np.linalg.svd(B, full_matrices=False)\n",
    "\n",
    "        Uk  = U[:, :samples]\n",
    "        Ubk = Ub[:, :samples]\n",
    "\n",
    "        # 1) “sqrt-leverage” = √(sum of squares)\n",
    "        levA = np.sqrt(np.sum(Uk**2,  axis=1))\n",
    "        levB = np.sqrt(np.sum(Ubk**2, axis=1))\n",
    "\n",
    "        # 2) normalize to get true probability distributions\n",
    "        pA = levA / levA.sum()\n",
    "        pB = levB / levB.sum()\n",
    "\n",
    "        # 3) random sample exactly k rows according to pA, pB\n",
    "        idxA = np.random.choice(m, size=samples, replace=False, p=pA)\n",
    "        idxB = np.random.choice(n, size=samples, replace=False, p=pB)\n",
    "\n",
    "        sampled_A = A[idxA, :]\n",
    "        sampled_B = B[idxB, :]\n",
    "\n",
    "        scaled_A = sampled_A * np.sqrt(m / samples)\n",
    "        scaled_B = sampled_B * np.sqrt(n / samples)\n",
    "\n",
    "        return scaled_A, scaled_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "uP-J6d_KNFv5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, Dict, Any\n",
    "\n",
    "class MatrixApproximationSampling:\n",
    "    def __init__(self, hash_size: int = 10000, seed: int = 42):\n",
    "        \"\"\"\n",
    "        Initializes the sampler with a random hash vector used for priority and threshold sampling.\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        self.hash = np.random.uniform(0, 1, size=hash_size)\n",
    "\n",
    "    def uniform_sampling(self, A: np.ndarray, B: np.ndarray, num_samples: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Uniformly samples rows from A and B to approximate A.T @ B.\n",
    "\n",
    "        For matrices A and B of shape (n, d), this method selects 'num_samples' rows uniformly at random,\n",
    "        scales them appropriately, and returns two matrices C and R such that C @ R approximates A.T @ B.\n",
    "        \n",
    "        C has shape (d, num_samples) and R has shape (num_samples, d), so the product C @ R is (d, d).\n",
    "        \"\"\"\n",
    "        # A and B must both be of shape (n, d)\n",
    "        n, d = A.shape\n",
    "        if B.shape != (n, d):\n",
    "            raise ValueError(\"A and B must have the same shape.\")\n",
    "        \n",
    "        # Initialize matrices: we store rows of A (transposed) in C and rows of B in R.\n",
    "        C = np.zeros((d, num_samples))\n",
    "        R = np.zeros((num_samples, d))\n",
    "        \n",
    "        # Compute scaling factor so the estimator is unbiased.\n",
    "        scaling = np.sqrt(n / num_samples)\n",
    "        \n",
    "        for t in range(num_samples):\n",
    "            idx = np.random.choice(n)  # sample uniformly from 0 to n-1\n",
    "            # Each column of C is the scaled sampled row of A (transposed).\n",
    "            C[:, t] = A[idx, :] * scaling\n",
    "            # Each row of R is the scaled sampled row of B.\n",
    "            R[t, :] = B[idx, :] * scaling\n",
    "        \n",
    "        return C, R\n",
    "\n",
    "    def priority_sampling(self, A: np.ndarray, num_samples: int) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Performs priority sampling on the rows of matrix A.\n",
    "\n",
    "        Returns a sketch with selected row indices, row values, and a threshold.\n",
    "        \"\"\"\n",
    "        n, d = A.shape\n",
    "        r = np.full(n, np.inf)\n",
    "\n",
    "        for i in range(n):\n",
    "            norm_sq = np.linalg.norm(A[i]) ** 2\n",
    "            if norm_sq > 0:\n",
    "                r[i] = self.hash[i] / norm_sq\n",
    "\n",
    "        threshold = np.partition(r, num_samples)[num_samples] if num_samples < n else np.inf\n",
    "\n",
    "        selected_indices = np.where(r < threshold)[0]\n",
    "        selected_rows = A[selected_indices]\n",
    "\n",
    "        return {\n",
    "            'indices': selected_indices,\n",
    "            'values': selected_rows,\n",
    "            'threshold': threshold\n",
    "        }\n",
    "\n",
    "    def threshold_sampling(self, A: np.ndarray, num_samples: int) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Performs threshold sampling based on row norms and a hash function.\n",
    "\n",
    "        Returns a sketch with selected row indices, row values, and a threshold value.\n",
    "        \"\"\"\n",
    "        n, d = A.shape\n",
    "        A_norm_sq = np.linalg.norm(A, 'fro') ** 2\n",
    "        tau = num_samples / A_norm_sq if A_norm_sq > 0 else float('inf')\n",
    "\n",
    "        selected_indices = []\n",
    "        selected_rows = []\n",
    "\n",
    "        for i in range(n):\n",
    "            row_norm_sq = np.linalg.norm(A[i]) ** 2\n",
    "            if self.hash[i] <= tau * row_norm_sq:\n",
    "                selected_indices.append(i)\n",
    "                selected_rows.append(A[i])\n",
    "\n",
    "        return {\n",
    "            'indices': np.array(selected_indices),\n",
    "            'values': np.array(selected_rows),\n",
    "            'threshold': tau\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def approximate_matrix_multiplication(sketch_A: Dict[str, Any], sketch_B: Dict[str, Any]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Approximates matrix multiplication using row sketches.\n",
    "        Only uses rows that are common to both A and B sketches.\n",
    "        \"\"\"\n",
    "        indices_A = sketch_A['indices']\n",
    "        indices_B = sketch_B['indices']\n",
    "        common_indices = np.intersect1d(indices_A, indices_B)\n",
    "\n",
    "        if common_indices.size == 0:\n",
    "            return np.zeros((sketch_A['values'].shape[1], sketch_B['values'].shape[1]))\n",
    "\n",
    "        result = np.zeros((sketch_A['values'].shape[1], sketch_B['values'].shape[1]))\n",
    "\n",
    "        for idx in common_indices:\n",
    "            i_A = np.where(indices_A == idx)[0][0]\n",
    "            i_B = np.where(indices_B == idx)[0][0]\n",
    "\n",
    "            row_A = sketch_A['values'][i_A]\n",
    "            row_B = sketch_B['values'][i_B]\n",
    "\n",
    "            norm_A = np.linalg.norm(row_A) ** 2\n",
    "            norm_B = np.linalg.norm(row_B) ** 2\n",
    "\n",
    "            # Multiply by thresholds instead of dividing\n",
    "            denom = min(1.0, norm_A * sketch_A['threshold'], norm_B * sketch_B['threshold'])\n",
    "\n",
    "            if denom > 0:\n",
    "                result += np.outer(row_A, row_B) / denom\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "7NiDIOmMN50u"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from typing import Dict\n",
    "\n",
    "class JLemma:\n",
    "    \"\"\"\n",
    "    Implements various Johnson-Lindenstrauss (JL) transform sketches:\n",
    "      - Gaussian JL\n",
    "      - PHD JL (using fast in-place FWHT)\n",
    "      - Count-Sketch JL\n",
    "    \"\"\"\n",
    "    def __init__(self, seed: int = None):\n",
    "        \"\"\"\n",
    "        seed: RNG seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def gaussian_JL(self, A: np.ndarray, B: np.ndarray, samples: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gaussian JL: Dense random projection to approximate A.T @ B.\n",
    "        \"\"\"\n",
    "        m, _ = A.shape\n",
    "        S = self.rng.normal(0, 1/np.sqrt(samples), size=(m, samples))\n",
    "        A_proj = A.T @ S    # (n x samples)\n",
    "        B_proj = B.T @ S    # (p x samples)\n",
    "        return A_proj @ B_proj.T  # (n x p)\n",
    "\n",
    "    @staticmethod\n",
    "    def _hadamard_transform(X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        In-place Fast Walsh–Hadamard Transform (FWHT) on each column of X.\n",
    "        Assumes X.shape[0] is a power of 2.\n",
    "        \"\"\"\n",
    "        M, p = X.shape\n",
    "        H = X.copy()\n",
    "        h = 1\n",
    "        while h < M:\n",
    "            for i in range(0, M, 2*h):\n",
    "                top = H[i:i+h, :]\n",
    "                bot = H[i+h:i+2*h, :]\n",
    "                H[i:i+h, :] = top + bot\n",
    "                H[i+h:i+2*h, :] = top - bot\n",
    "            h *= 2\n",
    "        return H\n",
    "\n",
    "    def PHD_JL(self, A: np.ndarray, B: np.ndarray, samples: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        PHD JL: Fast JL using randomized Hadamard + subsampling.\n",
    "        Approximates A.T @ B by (S H D A)^T (S H D B).\n",
    "        samples: sketch dimension t (with replacement sampling).\n",
    "        \"\"\"\n",
    "        n, p1 = A.shape\n",
    "        _, p2 = B.shape\n",
    "        t = samples\n",
    "        # Pad to power of two\n",
    "        mprime = 1 << ((n - 1).bit_length())\n",
    "        if mprime > n:\n",
    "            A_pad = np.zeros((mprime, p1), dtype=A.dtype)\n",
    "            B_pad = np.zeros((mprime, p2), dtype=B.dtype)\n",
    "            A_pad[:n, :] = A\n",
    "            B_pad[:n, :] = B\n",
    "        else:\n",
    "            A_pad = A.copy()\n",
    "            B_pad = B.copy()\n",
    "        # Random sign flip D\n",
    "        signs = self.rng.choice([-1, 1], size=mprime)\n",
    "        A_signed = A_pad * signs[:, None]\n",
    "        B_signed = B_pad * signs[:, None]\n",
    "        # Hadamard transform H\n",
    "        A_h = JLemma._hadamard_transform(A_signed)  # (mprime x p1)\n",
    "        B_h = JLemma._hadamard_transform(B_signed)  # (mprime x p2)\n",
    "        # Normalize by sqrt(m' * t)\n",
    "        norm = 1.0 / math.sqrt(mprime * t)\n",
    "        A_h *= norm\n",
    "        B_h *= norm\n",
    "        # Sample t rows with replacement\n",
    "        idx = self.rng.integers(0, mprime, size=t)\n",
    "        A_s = A_h[idx, :]  # (t x p1)\n",
    "        B_s = B_h[idx, :]  # (t x p2)\n",
    "        # Approximate product\n",
    "        return A_s.T @ B_s  # (p1 x p2)\n",
    "\n",
    "    def countsketch_JL(self, A: np.ndarray, B: np.ndarray, s: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Count-Sketch JL: Sparse projection via hashing and sign-flip.\n",
    "        \"\"\"\n",
    "        m, p1 = A.shape\n",
    "        _, p2 = B.shape\n",
    "        h = self.rng.integers(0, s, size=m)\n",
    "        sigma = self.rng.choice([-1, 1], size=m)\n",
    "        A_s = np.zeros((p1, s), dtype=A.dtype)\n",
    "        B_s = np.zeros((p2, s), dtype=B.dtype)\n",
    "        for i in range(m):\n",
    "            b = h[i]\n",
    "            A_s[:, b] += sigma[i] * A[i, :]\n",
    "            B_s[:, b] += sigma[i] * B[i, :]\n",
    "        return A_s @ B_s.T  # (p1 x p2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "uIkOLoVdloIX"
   },
   "outputs": [],
   "source": [
    "#all the four matrices\n",
    "\"\"\"\n",
    "There are two key properties being considered here:\n",
    "\n",
    "1. Leverage Score Distribution\n",
    "Uniform leverage scores → all rows are equally “important”\n",
    "\n",
    "Non-uniform leverage scores → some rows are more “important” than others\n",
    "\n",
    "2. Condition Number (κ / kappa)\n",
    "Good condition number (low κ) → matrix is stable for computation\n",
    "\n",
    "Bad condition number (high κ) → matrix is numerically unstable, more sensitive to error\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Case 1: Good Condition Number (kappa = 1e-8)\n",
    "good_condition = MatrixGeneration(10000, 100, 1e-8)\n",
    "A_uniform_good = good_condition.ug_matrix()\n",
    "B_uniform_good = good_condition.ug_matrix()\n",
    "A_nonuniform_good = good_condition.nb_matrix()\n",
    "B_nonuniform_good = good_condition.nb_matrix()\n",
    "\n",
    "# Case 2: Bad Condition Number (kappa = 10)\n",
    "bad_condition = MatrixGeneration(10000, 100, 10)\n",
    "A_uniform_bad = bad_condition.ug_matrix()\n",
    "B_uniform_bad = bad_condition.ug_matrix()\n",
    "A_nonuniform_bad = bad_condition.nb_matrix()\n",
    "B_nonuniform_bad = bad_condition.nb_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nYBjDgD-PA3a"
   },
   "outputs": [],
   "source": [
    "sample_sizes = [250, 500, 750, 1000, 1250, 1500, 1750, 2000]\n",
    "iterations = 5\n",
    "\n",
    "matrix_types = [\n",
    "    (\"Uniform Good\", 1e-8, \"ug_matrix\"),\n",
    "    (\"Uniform Bad\", 10, \"ug_matrix\"),\n",
    "    (\"Non-uniform Good\", 1e-8, \"nb_matrix\"),\n",
    "    (\"Non-uniform Bad\", 10, \"nb_matrix\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxpmj_I8Pf8M",
    "outputId": "ca010ddb-df49-4366-cf17-63db1da656ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matrix Types: 100%|██████████| 4/4 [02:16<00:00, 34.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to paper_implementation.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "results = []\n",
    "\n",
    "# Assume matrix_types, sample_sizes, iterations, MatrixGeneration,\n",
    "# MatrixApproximationLeverage, MatrixApproximationSampling, and JLemma \n",
    "# are defined elsewhere in your notebook.\n",
    "\n",
    "for matrix_name, kappa, gen_method in tqdm(matrix_types, desc=\"Matrix Types\"):\n",
    "    generator = MatrixGeneration(10000, 100, kappa)\n",
    "    A = getattr(generator, gen_method)()\n",
    "    B = getattr(generator, gen_method)()\n",
    "\n",
    "    A_frob = np.linalg.norm(A, 'fro')\n",
    "    B_frob = np.linalg.norm(B, 'fro')\n",
    "    original_product = A.T @ B\n",
    "\n",
    "    for size in sample_sizes:\n",
    "        for i in range(iterations):\n",
    "            \n",
    "            def add_row(method_name, approx_matrix, duration):\n",
    "                # Fix: Compute relative error as norm(diff) / (A_frob * B_frob)\n",
    "                diff = approx_matrix - original_product\n",
    "                rel_error = np.linalg.norm(diff, 'fro') / (A_frob * B_frob)\n",
    "                results.append({\n",
    "                    \"matrix\": matrix_name,\n",
    "                    \"sample_size\": size,\n",
    "                    \"iteration\": i + 1,\n",
    "                    \"method\": method_name,\n",
    "                    \"time\": duration,\n",
    "                    \"frobenius_norm\": np.linalg.norm(approx_matrix, 'fro'),\n",
    "                    \"relative_error\": rel_error\n",
    "                })\n",
    "            \n",
    "            # Leverage Sampling\n",
    "            start = time.time()\n",
    "            S_a, S_b = MatrixApproximationLeverage.leverage_score_sampling(A, B, size)\n",
    "            end = time.time()\n",
    "            add_row(\"Leverage Sampling\", S_a.T @ S_b, end - start)\n",
    "            \n",
    "            # Sqrt Leverage Sampling\n",
    "            start = time.time()\n",
    "            S_a, S_b = MatrixApproximationLeverage.sqrt_leverage_score_sampling(A, B, size)\n",
    "            end = time.time()\n",
    "            add_row(\"Sqrt Leverage Sampling\", S_a.T @ S_b, end - start)\n",
    "            \n",
    "            # Priority Sampling\n",
    "            sampler = MatrixApproximationSampling()\n",
    "            start = time.time()\n",
    "            S_a = sampler.priority_sampling(A, size)\n",
    "            S_b = sampler.priority_sampling(B, size)\n",
    "            approx = sampler.approximate_matrix_multiplication(S_a, S_b)\n",
    "            end = time.time()\n",
    "            add_row(\"Priority Sampling\", approx, end - start)\n",
    "            \n",
    "            # Threshold Sampling\n",
    "            start = time.time()\n",
    "            S_a = sampler.threshold_sampling(A, size)\n",
    "            S_b = sampler.threshold_sampling(B, size)\n",
    "            approx = sampler.approximate_matrix_multiplication(S_a, S_b)\n",
    "            end = time.time()\n",
    "            add_row(\"Threshold Sampling\", approx, end - start)\n",
    "            \n",
    "            # Uniform Sampling\n",
    "            start = time.time()\n",
    "            S_a, S_b = sampler.uniform_sampling(A, B, size)\n",
    "            end = time.time()\n",
    "            add_row(\"Uniform Sampling\", S_a @ S_b, end - start)\n",
    "            \n",
    "            # Gaussian JL\n",
    "            lemma = JLemma()\n",
    "            start = time.time()\n",
    "            G = lemma.gaussian_JL(A, B, size)\n",
    "            end = time.time()\n",
    "            add_row(\"Gaussian JL\", G, end - start)\n",
    "            \n",
    "            # PHD JL with Hadamard\n",
    "            start = time.time()\n",
    "            P = lemma.PHD_JL(A, B, size)  # Ensure your implementation supports Hadamard mode\n",
    "            end = time.time()\n",
    "            add_row(\"PHD JL (Hadamard)\", P, end - start)\n",
    "            \n",
    "            # CountSketch JL\n",
    "            start = time.time()\n",
    "            C = lemma.countsketch_JL(A, B, size)\n",
    "            end = time.time()\n",
    "            add_row(\"CountSketch JL\", C, end - start)\n",
    "\n",
    "# Save the final results to \"paper_implementation.csv\"\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"paper_implementation.csv\", index=False)\n",
    "print(\"Results saved to paper_implementation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped Data Preview:\n",
      "            matrix  sample_size             method  mean_error     std_error  \\\n",
      "0  Non-uniform Bad          250     CountSketch JL    0.063548  1.077469e-03   \n",
      "1  Non-uniform Bad          250        Gaussian JL    0.063728  1.385415e-03   \n",
      "2  Non-uniform Bad          250  Leverage Sampling    0.053535  4.544510e-04   \n",
      "3  Non-uniform Bad          250  PHD JL (Hadamard)    0.010157  2.048497e-09   \n",
      "4  Non-uniform Bad          250  Priority Sampling    0.062410  0.000000e+00   \n",
      "\n",
      "   mean_time  std_time  \n",
      "0   0.052026  0.010837  \n",
      "1   0.058152  0.004801  \n",
      "2   0.141318  0.043229  \n",
      "3   0.160593  0.003449  \n",
      "4   0.054985  0.007981  \n",
      "Relative error plots saved to 'plots/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"paper_implementation.csv\")\n",
    "\n",
    "# Ensure sample_size is numeric\n",
    "df[\"sample_size\"] = pd.to_numeric(df[\"sample_size\"], errors=\"coerce\")\n",
    "\n",
    "# Group by matrix, sample_size, and method to compute mean and std for relative error\n",
    "grouped = (\n",
    "    df.groupby([\"matrix\", \"sample_size\", \"method\"], as_index=False)\n",
    "      .agg(mean_error=(\"relative_error\", \"mean\"),\n",
    "           std_error=(\"relative_error\", \"std\"),\n",
    "           mean_time=(\"time\", \"mean\"),\n",
    "           std_time=(\"time\", \"std\"))\n",
    ")\n",
    "\n",
    "print(\"Grouped Data Preview:\")\n",
    "print(grouped.head())\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "output_dir = \"plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save plots for relative error\n",
    "unique_matrices = grouped[\"matrix\"].unique()\n",
    "\n",
    "for mat_name in unique_matrices:\n",
    "    matrix_df = grouped[grouped[\"matrix\"] == mat_name].copy()\n",
    "    if matrix_df.empty:\n",
    "        print(f\"No data found for matrix: {mat_name}\")\n",
    "        continue\n",
    "\n",
    "    matrix_df.sort_values(by=\"sample_size\", inplace=True)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.lineplot(\n",
    "        data=matrix_df,\n",
    "        x=\"sample_size\",\n",
    "        y=\"mean_error\",\n",
    "        hue=\"method\",\n",
    "        marker=\"o\",\n",
    "        markersize=8,\n",
    "        linewidth=2\n",
    "    )\n",
    "    \n",
    "    # Add error bars manually\n",
    "    for method in matrix_df[\"method\"].unique():\n",
    "        sub_df = matrix_df[matrix_df[\"method\"] == method]\n",
    "        plt.errorbar(\n",
    "            sub_df[\"sample_size\"],\n",
    "            sub_df[\"mean_error\"],\n",
    "            yerr=sub_df[\"std_error\"],\n",
    "            fmt=\"none\",\n",
    "            ecolor=\"gray\",\n",
    "            elinewidth=1.5,\n",
    "            capsize=3\n",
    "        )\n",
    "    \n",
    "    plt.title(f\"Relative Error vs. Sample Size for Matrix: {mat_name}\", fontsize=16)\n",
    "    plt.xlabel(\"Sample Size\", fontsize=14)\n",
    "    plt.ylabel(\"Relative Error\", fontsize=14)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Method\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    filename = f\"matrix_{mat_name.replace(' ', '_')}_error_plot.png\"\n",
    "    plt.savefig(os.path.join(output_dir, filename), dpi=300)\n",
    "    plt.close()\n",
    "    plt.show()\n",
    "\n",
    "print(f\"Relative error plots saved to '{output_dir}/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time plots saved to 'plots/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"paper_implementation.csv\")\n",
    "\n",
    "# Ensure sample_size is numeric\n",
    "df[\"sample_size\"] = pd.to_numeric(df[\"sample_size\"], errors=\"coerce\")\n",
    "\n",
    "# Group by matrix, sample_size, and method to compute mean and std for time\n",
    "grouped = (\n",
    "    df.groupby([\"matrix\", \"sample_size\", \"method\"], as_index=False)\n",
    "      .agg(mean_time=(\"time\", \"mean\"),\n",
    "           std_time=(\"time\", \"std\"))\n",
    ")\n",
    "\n",
    "# Set a clean style\n",
    "sns.set_style(\"whitegrid\")\n",
    "output_dir = \"plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save plots for computation time\n",
    "unique_matrices = grouped[\"matrix\"].unique()\n",
    "\n",
    "for mat_name in unique_matrices:\n",
    "    matrix_df = grouped[grouped[\"matrix\"] == mat_name].copy()\n",
    "    if matrix_df.empty:\n",
    "        print(f\"No data found for matrix: {mat_name}\")\n",
    "        continue\n",
    "    \n",
    "    matrix_df.sort_values(by=\"sample_size\", inplace=True)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.lineplot(\n",
    "        data=matrix_df,\n",
    "        x=\"sample_size\",\n",
    "        y=\"mean_time\",\n",
    "        hue=\"method\",\n",
    "        marker=\"o\",\n",
    "        markersize=8,\n",
    "        linewidth=2\n",
    "    )\n",
    "    \n",
    "    # Add error bars for time\n",
    "    for method in matrix_df[\"method\"].unique():\n",
    "        sub_df = matrix_df[matrix_df[\"method\"] == method]\n",
    "        plt.errorbar(\n",
    "            sub_df[\"sample_size\"],\n",
    "            sub_df[\"mean_time\"],\n",
    "            yerr=sub_df[\"std_time\"],\n",
    "            fmt=\"none\",\n",
    "            ecolor=\"gray\",\n",
    "            elinewidth=1.5,\n",
    "            capsize=3\n",
    "        )\n",
    "\n",
    "    plt.title(f\"Computation Time vs. Sample Size for Matrix: {mat_name}\", fontsize=16)\n",
    "    plt.xlabel(\"Sample Size\", fontsize=14)\n",
    "    plt.ylabel(\"Mean Time (s)\", fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Method\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = f\"matrix_{mat_name.replace(' ', '_')}_time_plot.png\"\n",
    "    plt.savefig(os.path.join(output_dir, filename), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Computation time plots saved to '{output_dir}/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matrix</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>iteration</th>\n",
       "      <th>method</th>\n",
       "      <th>time</th>\n",
       "      <th>frobenius_norm</th>\n",
       "      <th>relative_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uniform Good</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>Leverage Sampling</td>\n",
       "      <td>0.054332</td>\n",
       "      <td>2.080475e+16</td>\n",
       "      <td>0.062989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uniform Good</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>Sqrt Leverage Sampling</td>\n",
       "      <td>0.057373</td>\n",
       "      <td>2.142545e+16</td>\n",
       "      <td>0.064803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uniform Good</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>Priority Sampling</td>\n",
       "      <td>0.052887</td>\n",
       "      <td>2.162665e+16</td>\n",
       "      <td>0.063835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uniform Good</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>Threshold Sampling</td>\n",
       "      <td>0.061015</td>\n",
       "      <td>2.177947e+16</td>\n",
       "      <td>0.064301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uniform Good</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>Uniform Sampling</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>2.127004e+16</td>\n",
       "      <td>0.062498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         matrix  sample_size  iteration                  method      time  \\\n",
       "0  Uniform Good          250          1       Leverage Sampling  0.054332   \n",
       "1  Uniform Good          250          1  Sqrt Leverage Sampling  0.057373   \n",
       "2  Uniform Good          250          1       Priority Sampling  0.052887   \n",
       "3  Uniform Good          250          1      Threshold Sampling  0.061015   \n",
       "4  Uniform Good          250          1        Uniform Sampling  0.004241   \n",
       "\n",
       "   frobenius_norm  relative_error  \n",
       "0    2.080475e+16        0.062989  \n",
       "1    2.142545e+16        0.064803  \n",
       "2    2.162665e+16        0.063835  \n",
       "3    2.177947e+16        0.064301  \n",
       "4    2.127004e+16        0.062498  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your dataframe is called df\n",
    "\n",
    "# List of matrix types you are interested in\n",
    "matrix_types = [\"Uniform Good\", \"Uniform Bad\", \"Non-uniform Good\", \"Non-uniform Bad\"]\n",
    "\n",
    "# Create an empty dictionary to store the separate DataFrames\n",
    "matrix_tables = {}\n",
    "\n",
    "# Loop through each matrix type\n",
    "for matrix_type in matrix_types:\n",
    "    # Filter for this matrix type and sample size of 2000\n",
    "    filtered_df = df[(df['matrix'] == matrix_type) & (df['sample_size'] == 2000)]\n",
    "    \n",
    "    # Group by 'method' and calculate the mean of 'relative_error' and 'time'\n",
    "    grouped = filtered_df.groupby('method').agg({\n",
    "        'relative_error': 'mean',\n",
    "        'time': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Sort by relative_error ascending\n",
    "    sorted_grouped = grouped.sort_values(by='relative_error', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    # Save to the dictionary\n",
    "    matrix_tables[matrix_type] = sorted_grouped\n",
    "\n",
    "# Now matrix_tables[\"Uniform Good\"], matrix_tables[\"Uniform Bad\"], etc. are your sorted tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\textbf{Uniform Good} Table:\n",
      "\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "method & relative_error & time \\\\\n",
      "\\midrule\n",
      "PHD JL (Hadamard) & 0.009969 & 0.174878 \\\\\n",
      "Threshold Sampling & 0.021311 & 0.126851 \\\\\n",
      "Priority Sampling & 0.021721 & 0.117339 \\\\\n",
      "Gaussian JL & 0.022363 & 0.374924 \\\\\n",
      "CountSketch JL & 0.022430 & 0.064586 \\\\\n",
      "Uniform Sampling & 0.022690 & 0.025237 \\\\\n",
      "Leverage Sampling & 0.024321 & 0.158274 \\\\\n",
      "Sqrt Leverage Sampling & 0.024500 & 0.076609 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\\textbf{Uniform Bad} Table:\n",
      "\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "method & relative_error & time \\\\\n",
      "\\midrule\n",
      "Threshold Sampling & 0.021157 & 0.127315 \\\\\n",
      "Priority Sampling & 0.021538 & 0.111438 \\\\\n",
      "Gaussian JL & 0.022376 & 0.367146 \\\\\n",
      "CountSketch JL & 0.022465 & 0.065128 \\\\\n",
      "Uniform Sampling & 0.022831 & 0.032680 \\\\\n",
      "Leverage Sampling & 0.024093 & 0.165971 \\\\\n",
      "Sqrt Leverage Sampling & 0.024430 & 0.065521 \\\\\n",
      "PHD JL (Hadamard) & 0.028490 & 0.168568 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\\textbf{Non-uniform Good} Table:\n",
      "\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "method & relative_error & time \\\\\n",
      "\\midrule\n",
      "Priority Sampling & 0.000000 & 0.106477 \\\\\n",
      "Threshold Sampling & 0.000000 & 0.057191 \\\\\n",
      "CountSketch JL & 0.019314 & 0.059267 \\\\\n",
      "Gaussian JL & 0.022406 & 0.368468 \\\\\n",
      "PHD JL (Hadamard) & 0.141421 & 0.188234 \\\\\n",
      "Sqrt Leverage Sampling & 0.178564 & 0.070082 \\\\\n",
      "Uniform Sampling & 0.343511 & 0.035310 \\\\\n",
      "Leverage Sampling & 0.367438 & 0.158096 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\\textbf{Non-uniform Bad} Table:\n",
      "\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "method & relative_error & time \\\\\n",
      "\\midrule\n",
      "PHD JL (Hadamard) & 0.010157 & 0.178646 \\\\\n",
      "Threshold Sampling & 0.021016 & 0.132278 \\\\\n",
      "Priority Sampling & 0.021466 & 0.106383 \\\\\n",
      "Gaussian JL & 0.022196 & 0.374879 \\\\\n",
      "CountSketch JL & 0.022483 & 0.067158 \\\\\n",
      "Uniform Sampling & 0.023017 & 0.030060 \\\\\n",
      "Sqrt Leverage Sampling & 0.024170 & 0.070355 \\\\\n",
      "Leverage Sampling & 0.025329 & 0.134564 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "matrix_types = [\"Uniform Good\", \"Uniform Bad\", \"Non-uniform Good\", \"Non-uniform Bad\"]\n",
    "matrix_tables = {}\n",
    "\n",
    "# Create separate tables\n",
    "for matrix_type in matrix_types:\n",
    "    filtered_df = df[(df['matrix'] == matrix_type) & (df['sample_size'] == 2000)]\n",
    "    \n",
    "    grouped = filtered_df.groupby('method').agg({\n",
    "        'relative_error': 'mean',\n",
    "        'time': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    sorted_grouped = grouped.sort_values(by='relative_error', ascending=True).reset_index(drop=True)\n",
    "    matrix_tables[matrix_type] = sorted_grouped\n",
    "\n",
    "# Now, generate LaTeX tables\n",
    "for matrix_type, table in matrix_tables.items():\n",
    "    print(f\"\\n\\\\textbf{{{matrix_type}}} Table:\\n\")\n",
    "    print(table.to_latex(index=False, float_format=\"%.6f\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
